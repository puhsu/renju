{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from skimage.transform import resize\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import *\n",
    "%matplotlib inline\n",
    "\n",
    "IMG_SIZE = 64\n",
    "DATA_PATH = './data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.npy\r\n",
      "train-1.npy\r\n",
      "train-2.npy\r\n",
      "train-3.npy\r\n",
      "train-4.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls data | grep .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = ['train-1.npy', 'train-2.npy', 'train-3.npy', 'train-4.npy']\n",
    "labels_remap = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to resize all images to same size in order too train network. We also save processed images for future sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, save=False, filename=None):\n",
    "    # resize all images to [IMG_SIZE x IMG_SIZE]\n",
    "    # \n",
    "    # if `save` is set to True: save processed data to `filename` file\n",
    "    #\n",
    "    # returns: \n",
    "    #    images -- np.array() of images\n",
    "    #    labels -- np.array() of image labels\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "\n",
    "    ind = 0    \n",
    "    for elem in tqdm(data):\n",
    "        img, label = elem\n",
    "\n",
    "        images.append(resize(img, (IMG_SIZE, IMG_SIZE), mode='constant'))\n",
    "        if label not in labels_remap:\n",
    "            labels_remap[label] = ind\n",
    "            ind += 1\n",
    "        labels.append(labels_remap[label])\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    if save:\n",
    "        np.savez(DATA_PATH + filename, images, labels)\n",
    "            \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83246/83246 [01:03<00:00, 1301.42it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = process_data(np.load('./data/train-1.npy'), save=True, filename='train-1')\n",
    "# if I want to reuse previously created data\n",
    "# data = np.load(DATA_PATH + 'train-1.npz')\n",
    "# x_train = data[data.files[0]]\n",
    "# y_train = data[data.files[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest model\n",
    "\n",
    "For ease of implementation I use Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# x_train = images\n",
    "# y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], IMG_SIZE, IMG_SIZE, 1)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "83246/83246 [==============================] - 342s - loss: 4.3698 - acc: 0.2311   \n",
      "Epoch 2/10\n",
      "83246/83246 [==============================] - 330s - loss: 1.3035 - acc: 0.6873   \n",
      "Epoch 3/10\n",
      "83246/83246 [==============================] - 337s - loss: 0.6991 - acc: 0.8196   \n",
      "Epoch 4/10\n",
      "83246/83246 [==============================] - 328s - loss: 0.4584 - acc: 0.8753   \n",
      "Epoch 5/10\n",
      "83246/83246 [==============================] - 321s - loss: 0.3249 - acc: 0.9072   \n",
      "Epoch 6/10\n",
      "83246/83246 [==============================] - 322s - loss: 0.2539 - acc: 0.9252   \n",
      "Epoch 7/10\n",
      "83246/83246 [==============================] - 357s - loss: 0.2029 - acc: 0.9379   \n",
      "Epoch 8/10\n",
      "83246/83246 [==============================] - 339s - loss: 0.1770 - acc: 0.9461   \n",
      "Epoch 9/10\n",
      "83246/83246 [==============================] - 320s - loss: 0.1521 - acc: 0.9530   \n",
      "Epoch 10/10\n",
      "83246/83246 [==============================] - 321s - loss: 0.1319 - acc: 0.9579   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fa38a90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=150,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83247/83247 [01:03<00:00, 1303.65it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = process_data(np.load('./data/train-4.npy'), save=True, filename='train-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.327417353323\n",
      "Test accuracy: 0.919456556994\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "83247/83247 [==============================] - 323s - loss: 0.5918 - acc: 0.8463   \n",
      "Epoch 2/5\n",
      "83247/83247 [==============================] - 320s - loss: 0.3281 - acc: 0.9062   \n",
      "Epoch 3/5\n",
      "83247/83247 [==============================] - 318s - loss: 0.2261 - acc: 0.9321   \n",
      "Epoch 4/5\n",
      "83247/83247 [==============================] - 318s - loss: 0.1683 - acc: 0.9481   \n",
      "Epoch 5/5\n",
      "83247/83247 [==============================] - 318s - loss: 0.1427 - acc: 0.9548   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1210f7a90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=150,\n",
    "          epochs=5,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "83247/83247 [==============================] - 350s - loss: 0.1590 - acc: 0.9517   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1326b2e80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=150,\n",
    "          epochs=1,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83247/83247 [01:03<00:00, 1304.40it/s]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "\n",
    "ind = 0    \n",
    "for img in tqdm(np.load('./data/test.npy')):\n",
    "    images.append(resize(img, (IMG_SIZE, IMG_SIZE), mode='constant'))\n",
    "\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images.reshape(images.shape[0], IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83232/83247 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fignafig = np.load('./data/test.npy')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_labels = {v: k for k, v in labels_remap.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "ind = 1\n",
    "for cl in pred_classes:\n",
    "    ans.append([ind, inv_labels[cl]])\n",
    "    ind += 1\n",
    "\n",
    "ans = np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1, 63955],\n",
       "       [    2, 64432],\n",
       "       [    3, 64709],\n",
       "       ..., \n",
       "       [83245, 59837],\n",
       "       [83246, 60602],\n",
       "       [83247, 59065]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pred.csv', index=False, header=['Id', 'Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "314px",
    "left": "902px",
    "right": "27px",
    "top": "120px",
    "width": "343px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
